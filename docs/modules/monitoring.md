# Monitoring Service

**Arquivo:** `ai-service/app/services/monitoring_service.py`  
**VersÃ£o:** 1.0.0  
**Data:** 16 Nov 2025

---

## O Que Faz

O Monitoring Service coleta, agrega e expÃµe **mÃ©tricas em tempo real** sobre o comportamento do sistema: latÃªncias, throughput, cache hit rate, estratÃ©gias usadas e erros.

**Problemas resolvidos:**
- Falta de visibilidade sobre performance
- Bottlenecks nÃ£o identificados
- Debugging difÃ­cil sem mÃ©tricas
- ImpossÃ­vel otimizar sem dados

---

## Como Funciona

### Arquitetura

```
Request â†’ track_request()
    â†“
Componentes executam
    â”œâ”€ Orchestrator â†’ track_latency("orchestrator", 0.001)
    â”œâ”€ RAG â†’ track_latency("rag", 0.52)
    â”œâ”€ Reranker â†’ track_latency("reranker", 0.10)
    â”œâ”€ LLM â†’ track_latency("llm", 2.76)
    â””â”€ Validator â†’ track_latency("validator", 0.000)
    â†“
Response â†’ track_success() ou track_error()
    â†“
MÃ©tricas agregadas em memÃ³ria
    â†“
Expostas via /metrics e /analytics
```

### Dados Coletados

**Por Request:**
- Request ID (UUID)
- Timestamp
- Query
- EstratÃ©gia usada
- LatÃªncias por componente
- Success/Error
- Cache hit/miss

**Agregados:**
- Total requests
- Total errors
- Cache hits/misses
- Throughput (req/min)
- LatÃªncias mÃ©dias e percentis (P50, P75, P90, P95)
- DistribuiÃ§Ã£o de estratÃ©gias

---

## Como Usar

### InicializaÃ§Ã£o

```python
from app.services.monitoring_service import monitoring_service

# Singleton - jÃ¡ inicializado automaticamente
```

### Track Request

```python
# InÃ­cio do request
request_id = monitoring_service.track_request(
    query="Como configurar Proxmox?",
    strategy="rag"
)

# request_id: UUID Ãºnico para este request
```

### Track Latency

```python
import time

# Medir latÃªncia de um componente
start = time.time()
result = rag_service.search(query)
latency = time.time() - start

monitoring_service.track_latency(
    component="rag",
    latency=latency
)
```

### Track Success/Error

```python
try:
    response = process_query(query)
    monitoring_service.track_success()
except Exception as e:
    monitoring_service.track_error(
        error_type=type(e).__name__,
        error_message=str(e)
    )
```

### Track Cache

```python
cached = cache_service.get(query)

if cached:
    monitoring_service.track_cache_hit()
else:
    monitoring_service.track_cache_miss()
```

---

## IntegraÃ§Ã£o no Sistema

### No Endpoint de Chat

```python
@app.post("/v1/chat")
async def chat(request: ChatRequest):
    query = request.messages[-1].content
    
    # 1. Decidir estratÃ©gia
    strategy = orchestrator.decide_strategy(query, [])
    
    # 2. Track request
    request_id = monitoring_service.track_request(query, strategy)
    
    try:
        # 3. Processar com tracking de latÃªncias
        
        # Orchestrator
        start = time.time()
        # ... orchestrator logic
        monitoring_service.track_latency("orchestrator", time.time() - start)
        
        # RAG
        if strategy == "rag":
            start = time.time()
            context = rag_service.search(query)
            monitoring_service.track_latency("rag", time.time() - start)
            
            # Reranker
            start = time.time()
            context = reranker_service.get_relevant_docs(query, context)
            monitoring_service.track_latency("reranker", time.time() - start)
        
        # LLM
        start = time.time()
        response = llm_service.generate(query, context)
        monitoring_service.track_latency("llm", time.time() - start)
        
        # Validator
        start = time.time()
        response = validator_service.validate_response(response)
        monitoring_service.track_latency("validator", time.time() - start)
        
        # 4. Track success
        monitoring_service.track_success()
        
        return {"response": response}
        
    except Exception as e:
        # 5. Track error
        monitoring_service.track_error(
            error_type=type(e).__name__,
            error_message=str(e)
        )
        raise
```

---

## MÃ©tricas Expostas

### GET /metrics

**DescriÃ§Ã£o:** MÃ©tricas Prometheus-style

**Response:**
```json
{
  "total_requests": 25,
  "total_errors": 0,
  "cache_hits": 10,
  "cache_misses": 15,
  "throughput_rpm": 0.42,
  "cache_hit_rate_pct": 40.0,
  "error_rate_pct": 0.0,
  
  "orchestrator_latency_avg": 0.0007,
  "orchestrator_latency_p95": 0.0013,
  
  "rag_latency_avg": 0.52,
  "rag_latency_p95": 7.68,
  
  "reranker_latency_avg": 0.10,
  "reranker_latency_p95": 0.60,
  
  "llm_latency_avg": 2.76,
  "llm_latency_p95": 7.72,
  
  "validator_latency_avg": 0.0,
  "validator_latency_p95": 0.0,
  
  "total_latency_avg": 2.02,
  "total_latency_p95": 7.07,
  
  "strategies": {
    "cache": 10,
    "rag": 5,
    "direct": 10
  },
  
  "error_types": {}
}
```

### GET /analytics

**DescriÃ§Ã£o:** Analytics detalhados

**Response:**
```json
{
  "overview": {
    "total_requests": 25,
    "success_rate": 100.0,
    "avg_latency": 2.02,
    "p50_latency": 0.63,
    "p95_latency": 7.07
  },
  
  "by_strategy": {
    "cache": {
      "count": 10,
      "avg_latency": 0.00,
      "success_rate": 100.0
    },
    "rag": {
      "count": 5,
      "avg_latency": 8.83,
      "success_rate": 100.0
    },
    "direct": {
      "count": 10,
      "avg_latency": 0.63,
      "success_rate": 100.0
    }
  },
  
  "components": {
    "orchestrator": {"avg": 0.0007, "p95": 0.0013},
    "rag": {"avg": 0.52, "p95": 7.68},
    "reranker": {"avg": 0.10, "p95": 0.60},
    "llm": {"avg": 2.76, "p95": 7.72},
    "validator": {"avg": 0.0, "p95": 0.0}
  },
  
  "errors": {
    "total": 0,
    "by_type": {}
  }
}
```

### POST /metrics/reset

**DescriÃ§Ã£o:** Reset mÃ©tricas (Ãºtil para testes)

**Response:**
```json
{
  "message": "Metrics reset successfully"
}
```

---

## MÃ©tricas Detalhadas

### LatÃªncias

**Componentes trackados:**
- `orchestrator` - DecisÃ£o de estratÃ©gia
- `rag` - Busca no ChromaDB
- `reranker` - Cross-encoder reranking
- `llm` - GeraÃ§Ã£o de resposta (vLLM)
- `validator` - ValidaÃ§Ã£o de query/response

**Percentis calculados:**
- P50 (mediana)
- P75
- P90
- P95

### Throughput

**FÃ³rmula:**
```python
throughput_rpm = total_requests / elapsed_minutes
```

**Exemplo:**
- 25 requests em 60 minutos = 0.42 req/min

### Cache Hit Rate

**FÃ³rmula:**
```python
hit_rate = cache_hits / (cache_hits + cache_misses) * 100
```

**Exemplo:**
- 10 hits + 15 misses = 40% hit rate

### Error Rate

**FÃ³rmula:**
```python
error_rate = total_errors / total_requests * 100
```

**Exemplo:**
- 0 errors / 25 requests = 0% error rate

---

## Resultados em ProduÃ§Ã£o

### MÃ©tricas Atuais (16 Nov, 12:30)

```json
{
  "total_requests": 25,
  "total_errors": 0,
  "cache_hit_rate": 40%,
  "error_rate": 0%,
  
  "latÃªncias": {
    "orchestrator": 0.0007s,
    "rag": 0.52s,
    "reranker": 0.10s,
    "llm": 2.76s,  â† Bottleneck
    "validator": 0.0s,
    "total": 2.02s
  },
  
  "estratÃ©gias": {
    "cache": 10 (40%),
    "rag": 5 (20%),
    "direct": 10 (40%)
  }
}
```

### Insights

**Bottleneck identificado:**
- **LLM: 2.76s** (136% do total)
- Oportunidade: Multi-instance vLLM

**Cache eficaz:**
- 40% hit rate apÃ³s poucas horas
- 481x speedup (9.63s â†’ 0.02s)

**Componentes eficientes:**
- Orchestrator: 0.0007s âš¡
- Validator: 0.0s âš¡
- Reranker: 0.10s âœ…

---

## ConfiguraÃ§Ã£o

### Habilitar/Desabilitar Tracking

```python
# app/services/monitoring_service.py

ENABLE_MONITORING = True  # False para desabilitar
```

### Ajustar Percentis

```python
# app/services/monitoring_service.py

def _calculate_percentile(values, percentile):
    # ImplementaÃ§Ã£o atual: numpy.percentile
    # Pode ajustar para outras bibliotecas
    pass
```

### Adicionar Novos Componentes

```python
# Adicionar tracking de novo componente
monitoring_service.track_latency("new_component", latency)

# SerÃ¡ automaticamente incluÃ­do em /metrics
```

---

## Troubleshooting

### Problema: MÃ©tricas nÃ£o aparecem

**Sintoma:** `/metrics` retorna valores zerados

**DiagnÃ³stico:**
```python
# Verificar se tracking estÃ¡ habilitado
print(monitoring_service.ENABLE_MONITORING)  # True?

# Verificar se requests estÃ£o sendo trackados
print(monitoring_service.total_requests)  # > 0?
```

**SoluÃ§Ã£o:**
1. Verificar `ENABLE_MONITORING = True`
2. Verificar se `track_request()` estÃ¡ sendo chamado
3. Verificar logs de erro

### Problema: LatÃªncias incorretas

**Sintoma:** LatÃªncias muito altas ou muito baixas

**Causa:** Tracking incorreto (start/end)

**SoluÃ§Ã£o:**
```python
# Usar context manager (futuro)
with monitoring_service.track("rag"):
    result = rag_service.search(query)

# Ou verificar time.time() calls
```

### Problema: MemÃ³ria crescendo

**Sintoma:** Uso de memÃ³ria aumenta continuamente

**Causa:** MÃ©tricas acumulando sem limite

**SoluÃ§Ã£o:**
```python
# Reset periÃ³dico (ex: diÃ¡rio)
monitoring_service.reset()

# Ou implementar rolling window
# (manter apenas Ãºltimas 1000 requests)
```

---

## Dashboard (Futuro)

### UI Planejada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BrainAll V2 - Monitoring Dashboard                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Requests    â”‚  â”‚ Success     â”‚  â”‚ Cache Hit   â”‚ â”‚
â”‚ â”‚ 1,250       â”‚  â”‚ 100%        â”‚  â”‚ 65%         â”‚ â”‚
â”‚ â”‚ â–² +15%      â”‚  â”‚ âœ…          â”‚  â”‚ â–² +10%      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚ LatÃªncias por Componente                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Orchestrator â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.001s     â”‚ â”‚
â”‚ â”‚ RAG          â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.52s      â”‚ â”‚
â”‚ â”‚ Reranker     â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.10s      â”‚ â”‚
â”‚ â”‚ LLM          â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 2.76s âš ï¸    â”‚ â”‚
â”‚ â”‚ Validator    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.000s     â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚ EstratÃ©gias (Ãºltimas 24h)                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸŸ¢ Cache: 40%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         â”‚ â”‚
â”‚ â”‚ ðŸ”µ RAG: 35%    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          â”‚ â”‚
â”‚ â”‚ ðŸŸ¡ Direct: 25% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚ Throughput (req/min)                               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚     â•±â•²                                          â”‚ â”‚
â”‚ â”‚    â•±  â•²      â•±â•²                                 â”‚ â”‚
â”‚ â”‚   â•±    â•²    â•±  â•²    â•±â•²                          â”‚ â”‚
â”‚ â”‚  â•±      â•²  â•±    â•²  â•±  â•²                         â”‚ â”‚
â”‚ â”‚ â•±        â•²â•±      â•²â•±    â•²                        â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tecnologias

- **Backend:** FastAPI (jÃ¡ implementado)
- **Frontend:** React + Recharts
- **AtualizaÃ§Ã£o:** WebSocket (real-time)
- **HistÃ³rico:** SQLite ou TimescaleDB

---

## PrÃ³ximos Passos

### Melhorias Planejadas

1. **Dashboard UI**
   - React + Recharts
   - Real-time updates (WebSocket)
   - Filtros por perÃ­odo

2. **Persistent Storage**
   - SQLite para histÃ³rico
   - Queries SQL para analytics
   - Retention policy (30 dias)

3. **Alerting**
   - Slack/Email notifications
   - Thresholds configurÃ¡veis
   - Ex: Error rate > 5% â†’ Alert

4. **Distributed Tracing**
   - OpenTelemetry integration
   - Trace IDs atravÃ©s de microservices
   - Jaeger UI

5. **Custom Metrics**
   - User-defined metrics
   - Business KPIs
   - Cost tracking (tokens, compute)

---

## ReferÃªncias

- Prometheus: https://prometheus.io/
- OpenTelemetry: https://opentelemetry.io/
- Grafana: https://grafana.com/

---

**Ãšltima AtualizaÃ§Ã£o:** 16 Nov 2025  
**Autor:** Manus AI  
**Status:** âœ… Production-Ready
