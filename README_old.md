# BrainAll V2 - Plano de ImplementaÃ§Ã£o Completo

**Data:** 15 Novembro 2025  
**Autor:** Manus AI  
**Cliente:** rkoj@underall.com  
**Projeto:** Sistema de Chat AI Multi-Modelo

---

## ğŸ“Š SUMÃRIO EXECUTIVO

Este documento consolida toda a anÃ¡lise de infraestrutura realizada e define o plano detalhado de implementaÃ§Ã£o do **BrainAll V2**, um sistema de chat AI multi-modelo com interface moderna (React/Lovable) e backend robusto distribuÃ­do na infraestrutura Hetzner.

### Progresso Atual

âœ… **Fase 1-4 Completas** (AnÃ¡lise e Planeamento)  
ğŸ”„ **Fase 5 Em Progresso** (ImplementaÃ§Ã£o)  
â³ **Fases 6-7 Pendentes** (IntegraÃ§Ã£o e Deployment)

---

## ğŸ¯ OBJECTIVO DO PROJETO

Construir um sistema de chat AI completo que:

1. **Suporte mÃºltiplos modelos LLM** (Llama, Mistral, GPT, Claude, etc.)
2. **Interface moderna e responsiva** (jÃ¡ desenvolvida no Lovable)
3. **Modo agente autÃ³nomo** com ferramentas (web search, code execution)
4. **Upload e processamento de ficheiros** (imagens, Ã¡udio, documentos)
5. **TranscriÃ§Ã£o de Ã¡udio** (Whisper)
6. **HistÃ³rico de conversas** persistente
7. **AutenticaÃ§Ã£o de utilizadores**
8. **EscalÃ¡vel e distribuÃ­do** na infraestrutura existente

---

## ğŸ—ï¸ ARQUITETURA FINAL APROVADA

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     HELSINKI DATACENTER (HEL1)                  â”‚
â”‚                     LatÃªncia interna: <1ms                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ GPU Server   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Storage Box  â”‚                    â”‚
â”‚  â”‚ (GEX130)     â”‚  0.48ms â”‚ (BX21 - 5TB) â”‚                    â”‚
â”‚  â”‚              â”‚         â”‚              â”‚                    â”‚
â”‚  â”‚ â€¢ vLLM       â”‚         â”‚ â€¢ Models     â”‚                    â”‚
â”‚  â”‚ â€¢ Whisper    â”‚         â”‚ â€¢ Uploads    â”‚                    â”‚
â”‚  â”‚ â€¢ Embeddings â”‚         â”‚ â€¢ Backups    â”‚                    â”‚
â”‚  â”‚ â€¢ Redis      â”‚         â”‚ â€¢ Logs       â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â”‚ 0.57ms                                              â”‚
â”‚         â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ prox-106     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ prox-101     â”‚                    â”‚
â”‚  â”‚ (AX102)      â”‚  0.57ms â”‚ (AX102)      â”‚                    â”‚
â”‚  â”‚              â”‚         â”‚              â”‚                    â”‚
â”‚  â”‚ â€¢ API        â”‚         â”‚ â€¢ PostgreSQL â”‚                    â”‚
â”‚  â”‚ â€¢ WebSocket  â”‚         â”‚ â€¢ Redis      â”‚                    â”‚
â”‚  â”‚ â€¢ Workers    â”‚         â”‚ â€¢ Bastion    â”‚                    â”‚
â”‚  â”‚ â€¢ Nginx      â”‚         â”‚ â€¢ Mail       â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DistribuiÃ§Ã£o de Responsabilidades

| Componente | Servidor | Papel | Recursos |
|------------|----------|-------|----------|
| **LLM Inference** | GPU Server | InferÃªncia multi-modelo (vLLM) | 24c CPU, 49GB VRAM, 120GB RAM |
| **Audio Transcription** | GPU Server | Whisper (transcriÃ§Ã£o) | GPU partilhada |
| **Text Embeddings** | GPU Server | Sentence transformers | GPU partilhada |
| **API Gateway** | prox-106 VM | Node.js + tRPC | 4c, 8GB RAM |
| **Backend API** | prox-106 VM | FastAPI ou Node.js | 16c, 32GB RAM |
| **Queue Workers** | prox-106 VM | BullMQ/Celery | 8c, 16GB RAM |
| **Nginx** | prox-106 VM | Reverse proxy + SSL | 4c, 8GB RAM |
| **PostgreSQL** | prox-101 VM | Database principal | 8c, 16GB RAM |
| **Redis** | prox-101 VM | Cache + sessions | 2c, 4GB RAM |
| **Storage** | Storage Box | Ficheiros centralizados | 5TB |
| **Bastion** | prox-101 VM | Sandbox de cÃ³digo | 8c, 16GB RAM (existente) |

---

## âœ… PROGRESSO ATÃ‰ AGORA

### Fase 1: AnÃ¡lise Profunda da Infraestrutura âœ…

**Completada:** 15 Nov 2025

#### Descobertas Principais

**GPU Server (65.21.33.83)**
```yaml
Hardware:
  CPU: Intel Xeon Gold 5412U (24c/48t)
  GPU: NVIDIA RTX 6000 Ada (49GB VRAM)
  RAM: 126 GB (120GB disponÃ­vel)
  Disco: 1.8TB NVMe (1.6TB livre)
  
Rede:
  IP PÃºblico: 65.21.33.83
  IP vSwitch: 192.168.100.130
  LatÃªncia Storage Box: 0.48ms
  
ServiÃ§os Ativos:
  - Ollama (57.6GB RAM - ineficiente!)
  - brain-api (Python)
  - Caddy (reverse proxy)
  
Modelos LLM (60GB):
  - llama3.3:70b (42GB)
  - mistral-nemo (7.1GB)
  - llama3.1:8b (4.9GB)
```

**Proxmox Cluster**
```yaml
prox-101 (AX102):
  CPU: AMD Ryzen 9 7950X3D (16c/32t)
  RAM: 125GB (56GB livre)
  Disco: 1.8TB NVMe
  LocalizaÃ§Ã£o: Helsinki (HEL1-DC7)
  VMs: 9 ativas (bastion, mail, staging, etc.)
  
prox-106 (AX102):
  CPU: AMD Ryzen 9 7950X3D (16c/32t)
  RAM: 124GB (118GB livre) â­ MAIS RECURSOS
  Disco: 1.8TB NVMe
  LocalizaÃ§Ã£o: Helsinki (HEL1-DC7)
  VMs: Poucas (ideal para BrainAll)
  
prox-102 (Server Auction):
  CPU: AMD Ryzen 9 3900 (12c/24t)
  RAM: 62GB (49GB livre)
  LocalizaÃ§Ã£o: Frankfurt (FSN1-DC7) âš ï¸ 25ms latÃªncia
  Uso: Ceph OSD + backups (nÃ£o real-time)
```

**Storage Box**
```yaml
Modelo: BX21
Capacidade: 5TB (0% usado - vazio!)
LocalizaÃ§Ã£o: Helsinki (HEL1-BX46)
LatÃªncia: 0.483ms (MELHOR de todos!)
Protocolos: SSH/SFTP, SMB/CIFS, WebDAV, rsync
Custo: â‚¬10.90/mÃªs
```

#### Problemas Identificados

1. âŒ **Disco GPU 100% cheio** (1.5TB brain_memory corrompido)
2. âŒ **Ollama ineficiente** (57GB RAM para 1 modelo)
3. âš ï¸ **Ceph HEALTH_WARN** (placement groups)
4. âš ï¸ **SeguranÃ§a** (PostgreSQL pÃºblico, portas expostas)
5. âš ï¸ **Bastion disco cheio** (6.7GB livres)

#### AÃ§Ãµes Tomadas

âœ… Apagado brain_memory corrompido (1.5TB libertados)  
âœ… Parado brain_api antigo  
âœ… Limpo cache (143GB libertados)  
âœ… **Total libertado: 1.6TB** (disco agora a 7%)

---

### Fase 2: EstratÃ©gia e IntegraÃ§Ã£o do Storage Box âœ…

**Completada:** 15 Nov 2025

#### AÃ§Ãµes Realizadas

1. âœ… **Password do Storage Box resetada**
   - Nova password: `nNnÃ¤7Z_/@kfS~Â°u`
   - Acesso SSH testado e funcional

2. âœ… **SSHFS instalado no GPU server**
   ```bash
   apt-get install -y sshfs
   ```

3. âœ… **Storage Box montado**
   ```bash
   Mount point: /mnt/storagebox
   LatÃªncia: 0.48ms
   Status: Montado e funcional
   ```

4. âœ… **Estrutura de diretÃ³rios criada**
   ```
   /mnt/storagebox/
   â”œâ”€â”€ models/       # Modelos LLM (60GB+)
   â”œâ”€â”€ uploads/      # Uploads de utilizadores
   â”œâ”€â”€ backups/      # Backups automÃ¡ticos
   â”œâ”€â”€ logs/         # Logs centralizados
   â””â”€â”€ datasets/     # Datasets de treino
   ```

5. ğŸ”„ **MigraÃ§Ã£o de modelos Ollama em progresso**
   ```
   Origem: /usr/share/ollama/.ollama (60GB)
   Destino: /mnt/storagebox/models/ollama/
   Velocidade: ~1.43 GB/s
   Progresso: 34% (em background)
   ETA: ~10-15 minutos
   ```

---

### Fase 3: Benchmarking de Servidores âœ…

**Completada:** 15 Nov 2025

#### Resultados de LatÃªncia

| Origem | Destino | LatÃªncia | AvaliaÃ§Ã£o |
|--------|---------|----------|-----------|
| GPU | prox-101 | 0.568ms | â­â­â­â­â­ |
| GPU | prox-106 | 0.844ms | â­â­â­â­â­ |
| GPU | bastion | 0.638ms | â­â­â­â­â­ |
| GPU | Storage Box | **0.483ms** | â­â­â­â­â­ MELHOR |
| GPU | prox-102 | 25.673ms | âš ï¸ AceitÃ¡vel |

**ConclusÃ£o:** Toda a infraestrutura em Helsinki tem latÃªncia <1ms (excelente para real-time).

#### Resultados de I/O

| Servidor | Write | Read | AvaliaÃ§Ã£o |
|----------|-------|------|-----------|
| GPU Server NVMe | 1.2 GB/s | 3.7 GB/s | â­â­â­â­â­ |
| prox-101 NVMe | 1.2 GB/s | 2.7 GB/s | â­â­â­â­â­ |
| Ceph Cluster | ~400 MB/s | ~700 MB/s | â­â­â­â­ |

**ConclusÃ£o:** NVMe local muito rÃ¡pido, Ceph funcional mas mais lento (esperado).

---

### Fase 4: Desenho da Arquitetura Final âœ…

**Completada e Aprovada:** 15 Nov 2025

#### DecisÃµes Arquitecturais

1. **Concentrar em Helsinki (HEL1)**
   - GPU, prox-101, prox-106, Storage Box
   - LatÃªncia <1ms entre todos
   - prox-102 (Frankfurt) apenas para backups

2. **Migrar de Ollama para vLLM**
   - Libertar 57GB RAM
   - Melhor performance
   - Suporte multi-modelo simultÃ¢neo

3. **Stack TecnolÃ³gico**
   - **Frontend:** React + Vite (Lovable - jÃ¡ pronto)
   - **API Gateway:** Node.js + tRPC (type-safe)
   - **AI Service:** Python + FastAPI
   - **Database:** PostgreSQL + Redis
   - **Queue:** BullMQ (Node.js)
   - **Inference:** vLLM (GPU)
   - **Transcription:** Whisper (GPU)
   - **Storage:** MinIO S3-compatible (Storage Box)

4. **DistribuiÃ§Ã£o de VMs**
   - **prox-106:** Backend (API, Workers, Nginx) - 118GB RAM livre!
   - **prox-101:** Database (PostgreSQL, Redis) - jÃ¡ tem vÃ¡rias VMs
   - **prox-102:** Backups e batch processing - Frankfurt

---

## ğŸš€ FASE 5: IMPLEMENTAÃ‡ÃƒO (EM PROGRESSO)

**Iniciada:** 15 Nov 2025  
**Status:** 20% completo

### 5.1 PreparaÃ§Ã£o da Infraestrutura

#### 5.1.1 Storage Box âœ…

- [x] Reset password
- [x] Instalar SSHFS no GPU server
- [x] Montar Storage Box
- [x] Criar estrutura de diretÃ³rios
- [ğŸ”„] Migrar modelos Ollama (em progresso)
- [ ] Configurar mount automÃ¡tico (/etc/fstab)
- [ ] Testar performance de I/O
- [ ] Configurar backups automÃ¡ticos

#### 5.1.2 GPU Server - vLLM

- [ ] Parar Ollama (libertar 57GB RAM)
- [ ] Instalar vLLM
  ```bash
  pip install vllm
  ```
- [ ] Configurar vLLM multi-modelo
  ```python
  # Carregar modelos do Storage Box
  models = [
      "llama3.3:70b",  # 40GB VRAM
      "mistral-nemo",  # 7GB VRAM
  ]
  ```
- [ ] Criar API endpoint
- [ ] Testar inferÃªncia
- [ ] Configurar como serviÃ§o systemd
- [ ] MonitorizaÃ§Ã£o (Prometheus)

#### 5.1.3 GPU Server - Whisper

- [ ] Instalar Whisper
  ```bash
  pip install openai-whisper
  ```
- [ ] Criar API endpoint
- [ ] Testar transcriÃ§Ã£o
- [ ] Integrar com vLLM (partilha GPU)

#### 5.1.4 Proxmox - Criar VMs

**prox-106 (Backend)**

VM 1: **vm-brainall-api**
```yaml
vCPU: 16 cores
RAM: 32 GB
Disco: 100 GB (Ceph)
OS: Ubuntu 24.04 LTS
IP: 192.168.100.50
ServiÃ§os: Node.js + tRPC, WebSocket
```

VM 2: **vm-brainall-workers**
```yaml
vCPU: 8 cores
RAM: 16 GB
Disco: 50 GB (Ceph)
OS: Ubuntu 24.04 LTS
IP: 192.168.100.51
ServiÃ§os: BullMQ workers, file processing
```

VM 3: **vm-brainall-nginx**
```yaml
vCPU: 4 cores
RAM: 8 GB
Disco: 50 GB (Ceph)
OS: Ubuntu 24.04 LTS
IP: 192.168.100.52
ServiÃ§os: Nginx, Certbot (Let's Encrypt)
```

**prox-101 (Database)**

VM 4: **vm-brainall-db**
```yaml
vCPU: 8 cores
RAM: 16 GB
Disco: 200 GB (Ceph)
OS: Ubuntu 24.04 LTS
IP: 192.168.100.53
ServiÃ§os: PostgreSQL 16, Redis 7
```

#### 5.1.5 Rede e Firewall

- [ ] Configurar IPs estÃ¡ticos (vSwitch VLAN 4000)
- [ ] Abrir portas necessÃ¡rias
  - 80, 443 (Nginx)
  - 8000 (vLLM API)
  - 8001 (Whisper API)
  - 5432 (PostgreSQL - interno)
  - 6379 (Redis - interno)
- [ ] Configurar iptables/firewall
- [ ] Fechar portas expostas (PostgreSQL pÃºblico)
- [ ] Consolidar acessos SSH

### 5.2 Backend API

#### 5.2.1 Estrutura do Projeto

```
brainall-v2/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                 # API Gateway (Node.js + tRPC)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auth.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ files.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ history.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ tsconfig.json
â”‚   â”‚
â”‚   â”œâ”€â”€ ai-service/          # AI Service (Python + FastAPI)
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ embeddings.py
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ workers/             # Queue Workers (Node.js + BullMQ)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ file-processor.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ audio-processor.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ image-processor.ts
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚
â”‚   â””â”€â”€ database/            # Database schemas e migrations
â”‚       â”œâ”€â”€ migrations/
â”‚       â”œâ”€â”€ seeds/
â”‚       â””â”€â”€ schema.sql
â”‚
â”œâ”€â”€ frontend/                # Frontend (React + Vite - do Lovable)
â”‚   â””â”€â”€ (jÃ¡ existente em page-navigator)
â”‚
â”œâ”€â”€ docker-compose.yml       # Desenvolvimento local
â””â”€â”€ README.md
```

#### 5.2.2 API Gateway (Node.js + tRPC)

**Tecnologias:**
- Node.js 22
- tRPC (type-safe API)
- Prisma (ORM)
- WebSocket (Socket.io)
- JWT (autenticaÃ§Ã£o)

**Endpoints principais:**

```typescript
// Chat
POST /api/chat/send
GET  /api/chat/history
WS   /api/chat/stream

// Auth
POST /api/auth/register
POST /api/auth/login
POST /api/auth/logout
GET  /api/auth/me

// Files
POST /api/files/upload
GET  /api/files/:id
DELETE /api/files/:id

// History
GET  /api/history/conversations
GET  /api/history/conversation/:id
DELETE /api/history/conversation/:id
```

#### 5.2.3 AI Service (Python + FastAPI)

**Tecnologias:**
- Python 3.11
- FastAPI
- vLLM (inferÃªncia)
- Whisper (transcriÃ§Ã£o)
- Sentence Transformers (embeddings)

**Endpoints principais:**

```python
# Inference
POST /v1/chat/completions  # OpenAI-compatible
POST /v1/completions
GET  /v1/models

# Transcription
POST /v1/audio/transcriptions

# Embeddings
POST /v1/embeddings
```

#### 5.2.4 Database Schema

**PostgreSQL Tables:**

```sql
-- Users
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    name VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Conversations
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255),
    model VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Messages
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID REFERENCES conversations(id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL, -- 'user' | 'assistant' | 'system'
    content TEXT NOT NULL,
    attachments JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Files
CREATE TABLE files (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    filename VARCHAR(255) NOT NULL,
    mimetype VARCHAR(100),
    size BIGINT,
    storage_path VARCHAR(500),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_conversations_user_id ON conversations(user_id);
CREATE INDEX idx_messages_conversation_id ON messages(conversation_id);
CREATE INDEX idx_files_user_id ON files(user_id);
```

### 5.3 IntegraÃ§Ã£o Frontend-Backend

#### 5.3.1 AdaptaÃ§Ãµes no Frontend (Lovable)

**Ficheiros a modificar:**

1. **src/lib/api.ts** - Cliente tRPC
   ```typescript
   import { createTRPCProxyClient, httpBatchLink } from '@trpc/client';
   
   export const api = createTRPCProxyClient({
     links: [
       httpBatchLink({
         url: 'https://brain.underall.com/api/trpc',
       }),
     ],
   });
   ```

2. **src/components/ChatArea.tsx** - Substituir mock por API real
   ```typescript
   const sendMessage = async (content: string) => {
     const response = await api.chat.send.mutate({
       conversationId,
       content,
       attachments,
     });
     // Handle streaming response
   };
   ```

3. **src/hooks/useAuth.ts** - AutenticaÃ§Ã£o real
   ```typescript
   export const useAuth = () => {
     const login = async (email: string, password: string) => {
       const { token } = await api.auth.login.mutate({ email, password });
       localStorage.setItem('token', token);
     };
   };
   ```

#### 5.3.2 WebSocket para Streaming

```typescript
// Frontend
const socket = io('wss://brain.underall.com');

socket.on('chat:stream', (chunk) => {
  appendToMessage(chunk.content);
});

// Backend
io.on('connection', (socket) => {
  socket.on('chat:send', async (data) => {
    const stream = await aiService.chat(data);
    for await (const chunk of stream) {
      socket.emit('chat:stream', chunk);
    }
  });
});
```

---

## ğŸ“… CRONOGRAMA DETALHADO

### Semana 1: Infraestrutura e ServiÃ§os AI

**Dias 1-2** (16-17 Nov)
- [ğŸ”„] MigraÃ§Ã£o modelos Ollama (em progresso)
- [ ] Configurar vLLM no GPU server
- [ ] Instalar Whisper
- [ ] Testar inferÃªncia e transcriÃ§Ã£o
- [ ] Criar VMs no Proxmox

**Dias 3-4** (18-19 Nov)
- [ ] Instalar PostgreSQL + Redis
- [ ] Criar schema da database
- [ ] Configurar Nginx + SSL
- [ ] Testar conectividade entre VMs

**Dias 5-7** (20-22 Nov)
- [ ] Desenvolver API Gateway (tRPC)
- [ ] Desenvolver AI Service (FastAPI)
- [ ] Integrar vLLM + Whisper
- [ ] Testes unitÃ¡rios

### Semana 2: Backend e IntegraÃ§Ã£o

**Dias 8-10** (23-25 Nov)
- [ ] Desenvolver Workers (BullMQ)
- [ ] Sistema de upload de ficheiros
- [ ] Processamento de Ã¡udio/imagem
- [ ] IntegraÃ§Ã£o com Storage Box

**Dias 11-13** (26-28 Nov)
- [ ] Adaptar frontend (Lovable)
- [ ] Implementar autenticaÃ§Ã£o
- [ ] WebSocket streaming
- [ ] Testes de integraÃ§Ã£o

**Dia 14** (29 Nov)
- [ ] Testes end-to-end
- [ ] CorreÃ§Ã£o de bugs
- [ ] OptimizaÃ§Ãµes

### Semana 3: Deployment e FinalizaÃ§Ã£o

**Dias 15-17** (30 Nov - 2 Dez)
- [ ] Deploy em produÃ§Ã£o
- [ ] Configurar monitorizaÃ§Ã£o
- [ ] Backups automÃ¡ticos
- [ ] DocumentaÃ§Ã£o

**Dias 18-21** (3-6 Dez)
- [ ] Testes de carga
- [ ] Ajustes de performance
- [ ] SeguranÃ§a (penetration testing)
- [ ] Handover final

---

## ğŸ’° ESTIMATIVA DE CUSTOS

### Custos Mensais

| Item | Custo | Notas |
|------|-------|-------|
| **GPU Server (GEX130)** | â‚¬350/mÃªs | Hetzner dedicado |
| **prox-101 (AX102)** | â‚¬120/mÃªs | Hetzner dedicado |
| **prox-106 (AX102)** | â‚¬120/mÃªs | Hetzner dedicado |
| **prox-102 (Auction)** | â‚¬80/mÃªs | Hetzner dedicado |
| **Storage Box (BX21)** | â‚¬10.90/mÃªs | 5TB |
| **APIs Externas** | â‚¬50-200/mÃªs | OpenAI, Anthropic (opcional) |
| **Total** | **â‚¬730-880/mÃªs** | Sem APIs: â‚¬680/mÃªs |

### Custos de Desenvolvimento

| Fase | Horas | Custo (estimado) |
|------|-------|------------------|
| AnÃ¡lise e Planeamento | 40h | Completo âœ… |
| Infraestrutura | 60h | Em progresso ğŸ”„ |
| Backend | 80h | Pendente â³ |
| IntegraÃ§Ã£o Frontend | 40h | Pendente â³ |
| Testes e Deployment | 40h | Pendente â³ |
| **Total** | **260h** | ~3-4 semanas |

---

## ğŸ”’ SEGURANÃ‡A

### Melhorias NecessÃ¡rias

1. **Fechar PostgreSQL pÃºblico**
   - Porta 54321 exposta (99K packets)
   - Mover para rede interna apenas

2. **Consolidar acessos SSH**
   - MÃºltiplas portas (2220, 2222, 2223)
   - Usar apenas bastion como jump host

3. **Firewall**
   - Limpar regras duplicadas
   - Configurar fail2ban
   - Rate limiting

4. **SSL/TLS**
   - Let's Encrypt (Certbot)
   - HTTPS obrigatÃ³rio
   - HSTS headers

5. **AutenticaÃ§Ã£o**
   - JWT tokens
   - Refresh tokens
   - Rate limiting (login attempts)

6. **Dados**
   - EncriptaÃ§Ã£o em repouso (database)
   - EncriptaÃ§Ã£o em trÃ¢nsito (TLS)
   - Backups encriptados

---

## ğŸ“Š MONITORIZAÃ‡ÃƒO

### MÃ©tricas a Monitorizar

**GPU Server:**
- GPU utilization (%)
- VRAM usage (GB)
- Inference latency (ms)
- Requests per second

**Backend:**
- API response time (ms)
- Error rate (%)
- Queue length
- Active connections

**Database:**
- Query performance
- Connection pool
- Disk usage
- Replication lag

**Storage:**
- Disk usage (GB)
- I/O throughput (MB/s)
- Latency (ms)

### Ferramentas

- **Prometheus** - MÃ©tricas
- **Grafana** - Dashboards
- **Loki** - Logs centralizados
- **Alertmanager** - Alertas

---

## ğŸ¯ PRÃ“XIMOS PASSOS IMEDIATOS

### Hoje (15 Nov)

1. âœ… Aguardar conclusÃ£o da migraÃ§Ã£o Ollama (~10 min)
2. [ ] Configurar mount automÃ¡tico Storage Box
3. [ ] Parar Ollama e libertar 57GB RAM
4. [ ] Instalar vLLM
5. [ ] Testar inferÃªncia bÃ¡sica

### AmanhÃ£ (16 Nov)

6. [ ] Criar VMs no prox-106
7. [ ] Instalar PostgreSQL + Redis no prox-101
8. [ ] Configurar Nginx + SSL
9. [ ] Iniciar desenvolvimento da API Gateway

---

## ğŸ“ NOTAS E DECISÃ•ES

### DecisÃµes TÃ©cnicas

1. **Node.js + tRPC** escolhido por:
   - Type-safety (TypeScript end-to-end)
   - ExperiÃªncia prÃ©via do utilizador (inteligencia-v2)
   - Performance adequada
   - Ecossistema maduro

2. **Python + FastAPI** para AI Service:
   - Melhor suporte para ML/AI libraries
   - vLLM, Whisper, Transformers
   - Async/await nativo
   - OpenAI-compatible API

3. **PostgreSQL** escolhido sobre MongoDB:
   - RelaÃ§Ãµes complexas (users, conversations, messages)
   - ACID compliance
   - Melhor para histÃ³rico de conversas
   - JSONB para flexibilidade

4. **vLLM** escolhido sobre Ollama:
   - Mais eficiente (menos RAM)
   - Melhor performance
   - Suporte multi-modelo simultÃ¢neo
   - API compatÃ­vel com OpenAI

### Riscos e MitigaÃ§Ãµes

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|---------------|---------|-----------|
| GPU overload | MÃ©dia | Alto | Rate limiting, queue system |
| Storage Box latÃªncia | Baixa | MÃ©dio | Cache local (Redis) |
| Ceph instabilidade | MÃ©dia | MÃ©dio | Backups regulares, monitorizaÃ§Ã£o |
| SeguranÃ§a | MÃ©dia | Alto | Firewall, SSL, autenticaÃ§Ã£o robusta |
| Complexidade | Alta | MÃ©dio | DocumentaÃ§Ã£o, testes, monitorizaÃ§Ã£o |

---

## ğŸ“š REFERÃŠNCIAS E DOCUMENTAÃ‡ÃƒO

### Tecnologias

- [vLLM Documentation](https://docs.vllm.ai/)
- [Whisper OpenAI](https://github.com/openai/whisper)
- [tRPC](https://trpc.io/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [BullMQ](https://docs.bullmq.io/)
- [Prisma](https://www.prisma.io/)

### Infraestrutura

- [Hetzner Docs](https://docs.hetzner.com/)
- [Proxmox VE](https://pve.proxmox.com/wiki/Main_Page)
- [Ceph Documentation](https://docs.ceph.com/)

---

**Documento gerado por:** Manus AI  
**Ãšltima atualizaÃ§Ã£o:** 15 Novembro 2025 - 02:00 GMT+1  
**VersÃ£o:** 1.0  
**Status:** ğŸ”„ Em progresso - Fase 5 (20% completo)
